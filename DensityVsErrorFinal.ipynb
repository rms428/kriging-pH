{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from arcpy.sa import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def roi(df, states, state_col = 'STATE_ABBR'):\n",
    "    \"\"\"\n",
    "    Returns Dataframe with only roi data\n",
    "    Params: Dataframe to filter; list of interested states; name of column where state info is stored\n",
    "    \"\"\"\n",
    "    new_df = df[df[state_col].isin(states)]\n",
    "    return new_df\n",
    "\n",
    "def landcover(df, land_type = 82):\n",
    "    \"\"\"\n",
    "    Returns a df with only the specified landcover (default in cultivated crops)\n",
    "    \"\"\"\n",
    "    filtered_df = df[df['landcover'] == land_type]\n",
    "    return filtered_df\n",
    "\n",
    "def valid(df, split, ID: str, col = 'Random', seed = 1):\n",
    "    \"\"\"\n",
    "    Makes a random subset of the data for validation\n",
    "    Params: Dataframe to filter; for split input of 20 yields 80:20 testing:validation split; name of column to be randomized\n",
    "    \"\"\"\n",
    "    if seed !=1:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    df[col] = np.random.randint(0,100, df.shape[0])\n",
    "    testing_df = df.loc[df[col] >= split].copy()\n",
    "    validation_df = df.loc[df[col] < split].copy()\n",
    "    testing_path = arcpy.env.workspace+'/test'+ID+'.csv'\n",
    "    validing_path = arcpy.env.workspace+'/valid'+ID+'.csv'\n",
    "    testing_df.to_csv(testing_path) \n",
    "    validation_df.to_csv(validing_path)\n",
    "    return testing_path, validing_path\n",
    "\n",
    "def setup(df, states, split, ID: str):\n",
    "    \"\"\"\n",
    "    Synopsis of roi, valid, and landcover to get testing and validation df's in roi with target land cover types.\n",
    "    \"\"\"\n",
    "    new_df = roi(df, states)\n",
    "    filtered_df = landcover(new_df)\n",
    "    return valid(filtered_df, split, ID)\n",
    "\n",
    "def toXY(in_table:str, out_points: str, ID: str):\n",
    "    \"\"\"\n",
    "    Returns XY points to run SpatialJoin and convert csv to points\n",
    "    \"\"\"\n",
    "    x_coords = \"longitude_decimal_degrees\"\n",
    "    y_coords = \"latitude_decimal_degrees\"\n",
    "    out_feature_class = out_points + ID\n",
    "\n",
    "    # Make the XY event layer...\n",
    "    arcpy.management.XYTableToPoint(in_table, out_feature_class,\n",
    "                                    x_coords, y_coords)\n",
    "    return out_feature_class\n",
    "\n",
    "def density(feat:str, join_features: str, r:int, out_put: str, ID:str):\n",
    "    \"\"\"\n",
    "    Returns edited feature class to be interpolated. Counts the density within certain radius, r.\n",
    "    Density, in this case, is defined as the number of points within a certain radius, r.\n",
    "    Params: Feature class from SpatialJoin, feat; r is the search radius\n",
    "    \"\"\"\n",
    "    # set the local variables\n",
    "    target_features = feat\n",
    "    out_feature_class = out_put + ID\n",
    "\n",
    "    arcpy.analysis.SpatialJoin(target_features, \n",
    "                               join_features,\n",
    "                               out_feature_class, \n",
    "                               join_operation = \"JOIN_ONE_TO_ONE\",\n",
    "                               join_type = \"KEEP_ALL\",\n",
    "                               match_option = \"WITHIN_A_DISTANCE\",\n",
    "                               search_radius = str(r)+\" Kilometers\")\n",
    "    return(out_feature_class)\n",
    "    \n",
    "def EBK(in_features: str, output: str, ID: str, z_field: str = \"ph_h2o\"):\n",
    "    \"\"\"\n",
    "    Returns pH raster across lower 48. \n",
    "    \"\"\"\n",
    "    out_raster = output + ID\n",
    "\n",
    "    arcpy.ga.EmpiricalBayesianKriging(in_features,\n",
    "                                      z_field,\n",
    "                                      out_raster)\n",
    "    return out_raster\n",
    "\n",
    "def toRaster(ga_layer:str, output: str, ID: str):\n",
    "    \"\"\"\n",
    "    Converts EBK to raster.\n",
    "    \"\"\"\n",
    "    in_geostat_layer = ga_layer\n",
    "    out_raster = output + ID\n",
    "    arcpy.ga.GALayerToRasters(in_geostat_layer, out_raster)\n",
    "    return out_raster\n",
    "\n",
    "def ExtractToPoints(points: str, raster: str, output: str, ID: str):\n",
    "    \"\"\"\n",
    "    Returns points for validation with their predicted pH from EBK raster.\n",
    "    \"\"\"\n",
    "    ExtractValuesToPoints(points, raster, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set workspace\n",
    "arcpy.env.workspace = r\"C:\\path_to_your.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# get NCSS and set ID (to keep track)\n",
    "ncss_path = \"NCSScompleter\"\n",
    "NCSS = pd.DataFrame.spatial.from_featureclass(ncss_path) \n",
    "NCSS.rename(columns={'RASTERVALU': 'landcover', 'PageNumber': 'CellID'}, inplace=True)\n",
    "ID = '6272'\n",
    "\n",
    "# IMPORTANT VARIABLES\n",
    "\n",
    "# set roi\n",
    "# cornbelt = ['IA', 'MO', 'IL', 'IN', 'OH']\n",
    "states = NCSS['STATE_ABBR']\n",
    "nation = states.unique()\n",
    "# set desired validation split\n",
    "split = 34\n",
    "# set radius (km)\n",
    "radius = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[9]:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# makes datasets\n",
    "test_path, valid_path = setup(NCSS, nation, split, ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_asXY = toXY(test_path, \"testing_points\", ID)\n",
    "validation_asXY = toXY(valid_path, \"validation_points\", ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's time to krig.\n",
    "ebk_totest = EBK(testing_asXY, \"EBK\", ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = toRaster(ebk_totest, \"EBKRas\", ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_spatjoin = density(testing_asXY, radius, \"count\", ID) (you never really use this)\n",
    "validation_spatjoin = density(validation_asXY, testing_asXY, radius, \"valid_with_count\", ID) # returns Join_Count column in feature class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "toAnalyze = ExtractToPoints(validation_spatjoin, raster, \"Analysis\", ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes df from feature class, edits columns to include only graphs\n",
    "analysis = pd.DataFrame.spatial.from_featureclass(toAnalyze) \n",
    "analysis.rename(columns={'RASTERVALU': 'predicted_pH'}, inplace=True)\n",
    "analysis['error'] = analysis['ph_h2o']-analysis['predicted_pH']\n",
    "analysis = analysis.filter(items = ['Join_Count', 'error'])\n",
    "# export\n",
    "# analysis.to_csv(r\"C:\\path_to_your.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "num1 = analysis.to_numpy()\n",
    "join_count = np.unique(num1[:, 0])\n",
    "\n",
    "counts = {}\n",
    "alldata = []\n",
    "for i, val in enumerate(join_count):\n",
    "    a = num1[num1[:, 0] == val, 1]\n",
    "    b = a[~pd.isna(a)]\n",
    "    c = np.abs(b)\n",
    "    alldata.append(np.array(c, dtype=float))\n",
    "    counts[val] = len(a)\n",
    "\n",
    "# plots\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "\n",
    "# plot box plot\n",
    "boxplot = ax.boxplot(alldata, sym=\"k.\")\n",
    "ax.set_title('Density vs Error', pad = 20)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks([y + 1 for y in range(len(alldata))], labels=join_count)\n",
    "ax.set_xlabel('# of points in radius ' + str(radius) + ' km')\n",
    "ax.set_ylabel('Error')\n",
    "\n",
    "max_y = max([whisker.get_ydata()[1] for whisker in boxplot['whiskers'][1::2]]) \n",
    "\n",
    "# Annotate the box plot with the number of points\n",
    "annotation_y = max_y + (max_y * 0.25)\n",
    "for i, (val, count) in enumerate(counts.items()):\n",
    "    ax.annotate(f'{count}', xy=(i + 1, annotation_y), xytext=(0, 0),\n",
    "                textcoords='offset points', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
